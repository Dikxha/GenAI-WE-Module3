{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae4KFs2X_sWR",
        "outputId": "b23b296b-27ca-4c47-f99d-c22b173b05d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.10/dist-packages (24.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzparxdj-wYW",
        "outputId": "74b7e60d-e00a-4626-923a-2b9b780b1dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lorem Ipsum text saved to 'LoremIpsum.txt'\n",
            "Tokens: ['Score', 'each', 'cause.', 'Quality', 'throughout', 'beautiful', 'instead.', 'Despite', 'measure', 'ago', 'current.', 'Determine', 'operation', 'speak', 'according', 'south', 'recently.', 'Everyone', 'democratic', 'shake', 'bill', 'here', 'grow.', 'Page', 'southern', 'role', 'movie', 'win', 'her.', 'Stop', 'peace', 'technology', 'officer', 'relate.', 'Product', 'significant', 'world.', 'Term', 'herself', 'law', 'street', 'class.', 'Prove', 'reduce', 'raise', 'author', 'play.', 'Rock', 'clear', 'here', 'writer', 'policy', 'news', 'range.', 'Director', 'allow', 'firm', 'environment.', 'Then', 'fire', 'pretty', 'how', 'trip', 'learn', 'enter.', 'Seat', 'much', 'section', 'investment', 'on.', 'Young', 'catch', 'management', 'sense', 'technology.', 'Physical', 'society', 'instead', 'as.', 'Other', 'life', 'edge', 'network', 'wall', 'quite.', 'Seem', 'shoulder', 'future', 'fall', 'citizen', 'about', 'reveal.', 'Will', 'seven', 'medical', 'blood', 'personal.', 'Current', 'hear', 'claim', 'well', 'two', 'truth', 'out', 'major.', 'Upon', 'these', 'story', 'film.', 'Drive', 'note', 'bad', 'rule.', 'She', 'campaign', 'little', 'near', 'enter', 'their', 'institution.', 'Up', 'sense', 'ready', 'require', 'human.', 'Tonight', 'later', 'easy', 'ask', 'again', 'network.', 'Detail', 'audience', 'piece', 'director', 'town', 'teacher', 'audience', 'draw.', 'Democrat', 'car', 'very', 'number', 'line', 'six', 'space.', 'Best', 'issue', 'interest', 'level.', 'Pull', 'worker', 'better.', 'Song', 'body', 'court', 'movie', 'cell', 'contain.', 'Economic', 'type', 'kitchen', 'technology', 'nearly', 'anything', 'yourself.', 'Why', 'unit', 'support.', 'Magazine', 'degree', 'husband', 'around', 'her', 'world.', 'Unit', 'size', 'expect', 'recent', 'room.', 'Choice', 'father', 'why', 'often', 'my', 'security', 'arm.', 'Live', 'try', 'most', 'arm', 'meet', 'surface', 'attention', 'attack.', 'Identify', 'walk', 'now', 'often', 'always.', 'Price', 'north', 'first', 'end', 'prove', 'fire.', 'How', 'public', 'feel', 'first', 'sell.', 'Leader', 'your', 'you.', 'Mrs', 'media', 'car', 'give.', 'Hard', 'citizen', 'street', 'region', 'particularly.', 'Account', 'stage', 'federal', 'professional', 'voice', 'care', 'break.', 'Choice', 'example', 'decision', 'garden', 'reach', 'table', 'measure.', 'Town', 'suffer', 'begin', 'interest', 'everybody.', 'Side', 'PM', 'energy', 'scientist', 'necessary', 'into.', 'Away', 'third', 'tough', 'nation.', 'Need', 'involve', 'among', 'half', 'value', 'win', 'always', 'group.', 'Project', 'government', 'nice', 'themselves', 'wind.', 'Understand', 'door', 'class', 'son.', 'Agent', 'say', 'forward', 'us', 'soon', 'ten.', 'Environment', 'skin', 'blue', 'the', 'teach.', 'Staff', 'least', 'figure', 'somebody', 'dinner.', 'Process', 'huge', 'everything.', 'Go', 'meeting', 'quickly', 'such', 'former.', 'Boy', 'wife', 'condition.', 'Board', 'its', 'rock.', 'Job', 'worker', 'break', 'tonight', 'couple', 'and.', 'Mind', 'southern', 'rather.', 'Hair', 'attorney', 'professional', 'form', 'finish.', 'Rest', 'feel', 'finally', 'impact.', 'Never', 'court', 'professor', 'here', 'security.', 'Past', 'feeling', 'nature', 'a.', 'Decision', 'size', 'parent', 'focus', 'kid.', 'List', 'top', 'somebody', 'college', 'be', 'middle', 'plan.', 'Behavior', 'weight', 'dog', 'financial', 'southern', 'challenge.', 'Worker', 'particularly', 'shoulder', 'lay', 'though.', 'Responsibility', 'himself', 'hundred', 'challenge', 'reach.', 'Sing', 'despite', 'sound', 'receive.', 'Anyone', 'eat', 'summer', 'lead', 'soon', 'property', 'write.', 'Wear', 'through', 'partner', 'rest', 'measure', 'store.', 'Knowledge', 'city', 'technology', 'late', 'seem', 'style', 'everyone.', 'Machine', 'dream', 'key', 'require', 'doctor', 'from', 'throw.', 'Catch', 'discuss', 'really', 'relationship.', 'Imagine', 'my', 'indeed', 'deal', 'information', 'toward.', 'Watch', 'affect', 'thing', 'offer', 'local', 'wall', 'fear', 'hope.', 'Section', 'national', 'owner', 'determine', 'detail', 'job', 'ahead.', 'Protect', 'something', 'right', 'subject', 'try', 'wonder.', 'Agree', 'hour', 'north', 'agree', 'poor', 'career', 'left.', 'Here', 'deep', 'force', 'seven', 'here.', 'Strong', 'like', 'see', 'appear', 'weight.', 'Practice', 'sit', 'prepare', 'senior', 'wear.', 'Stuff', 'perform', 'draw', 'list', 'boy.', 'Record', 'short', 'cold', 'parent', 'security', 'boy', 'standard.', 'Blue', 'agent', 'find', 'quality', 'when.', 'Away', 'real', 'physical', 'big', 'significant.', 'South', 'someone', 'not', 'American', 'mouth', 'product', 'attention', 'positive.', 'Support', 'state', 'black.', 'Religious', 'itself', 'safe', 'whole', 'establish', 'space', 'Mrs.', 'Let', 'stay', 'or', 'focus', 'early', 'various', 'everything.', 'During', 'let', 'particular', 'her', 'agreement', 'surface', 'consider.', 'Something', 'future', 'they', 'red', 'everybody', 'act.', 'Beat', 'result', 'major', 'serve', 'real.', 'Society', 'behavior', 'develop', 'reality', 'fill', 'ok', 'list.', 'Gas', 'you', 'nearly', 'goal', 'law', 'fill', 'discover.', 'Firm', 'sea', 'week', 'real', 'course.', 'Right', 'with', 'modern', 'executive', 'beyond.', 'Fast', 'guess', 'few', 'remain', 'call.', 'Window', 'network', 'recently.', 'Bill', 'activity', 'expect', 'long', 'future', 'whole', 'education.', 'Box', 'assume', 'man', 'officer', 'rather', 'charge', 'specific.', 'Yes', 'budget', 'share', 'paper.', 'Difficult', 'mission', 'late', 'kind', 'team', 'wrong', 'figure', 'perform.', 'Way', 'debate', 'decision', 'produce.', 'Dream', 'necessary', 'choose', 'impact.', 'Like', 'allow', 'explain', 'executive', 'teacher', 'author', 'do', 'enough.', 'Operation', 'sound', 'cup', 'boy', 'different', 'chance', 'enter', 'central.', 'Society', 'organization', 'station', 'TV.', 'Buy', 'read', 'record', 'wall', 'matter', 'management.', 'Always', 'it', 'focus', 'economy', 'before', 'while', 'structure', 'offer.', 'Yourself', 'public', 'especially.', 'Like', 'prepare', 'trouble', 'consider.', 'Play', 'man', 'before', 'girl', 'four', 'prove.', 'Form', 'really', 'explain', 'war.', 'Already', 'because', 'education', 'break', 'significant', 'ten', 'stay.', 'Price', 'my', 'including.', 'Gun', 'series', 'personal', 'service', 'data', 'near', 'until.', 'Thing', 'machine', 'ahead', 'picture', 'son', 'report.']\n",
            "Chain: {('Score', 'each'): ['cause.'], ('each', 'cause.'): ['Quality'], ('cause.', 'Quality'): ['throughout'], ('Quality', 'throughout'): ['beautiful'], ('throughout', 'beautiful'): ['instead.'], ('beautiful', 'instead.'): ['Despite'], ('instead.', 'Despite'): ['measure'], ('Despite', 'measure'): ['ago'], ('measure', 'ago'): ['current.'], ('ago', 'current.'): ['Determine'], ('current.', 'Determine'): ['operation'], ('Determine', 'operation'): ['speak'], ('operation', 'speak'): ['according'], ('speak', 'according'): ['south'], ('according', 'south'): ['recently.'], ('south', 'recently.'): ['Everyone'], ('recently.', 'Everyone'): ['democratic'], ('Everyone', 'democratic'): ['shake'], ('democratic', 'shake'): ['bill'], ('shake', 'bill'): ['here'], ('bill', 'here'): ['grow.'], ('here', 'grow.'): ['Page'], ('grow.', 'Page'): ['southern'], ('Page', 'southern'): ['role'], ('southern', 'role'): ['movie'], ('role', 'movie'): ['win'], ('movie', 'win'): ['her.'], ('win', 'her.'): ['Stop'], ('her.', 'Stop'): ['peace'], ('Stop', 'peace'): ['technology'], ('peace', 'technology'): ['officer'], ('technology', 'officer'): ['relate.'], ('officer', 'relate.'): ['Product'], ('relate.', 'Product'): ['significant'], ('Product', 'significant'): ['world.'], ('significant', 'world.'): ['Term'], ('world.', 'Term'): ['herself'], ('Term', 'herself'): ['law'], ('herself', 'law'): ['street'], ('law', 'street'): ['class.'], ('street', 'class.'): ['Prove'], ('class.', 'Prove'): ['reduce'], ('Prove', 'reduce'): ['raise'], ('reduce', 'raise'): ['author'], ('raise', 'author'): ['play.'], ('author', 'play.'): ['Rock'], ('play.', 'Rock'): ['clear'], ('Rock', 'clear'): ['here'], ('clear', 'here'): ['writer'], ('here', 'writer'): ['policy'], ('writer', 'policy'): ['news'], ('policy', 'news'): ['range.'], ('news', 'range.'): ['Director'], ('range.', 'Director'): ['allow'], ('Director', 'allow'): ['firm'], ('allow', 'firm'): ['environment.'], ('firm', 'environment.'): ['Then'], ('environment.', 'Then'): ['fire'], ('Then', 'fire'): ['pretty'], ('fire', 'pretty'): ['how'], ('pretty', 'how'): ['trip'], ('how', 'trip'): ['learn'], ('trip', 'learn'): ['enter.'], ('learn', 'enter.'): ['Seat'], ('enter.', 'Seat'): ['much'], ('Seat', 'much'): ['section'], ('much', 'section'): ['investment'], ('section', 'investment'): ['on.'], ('investment', 'on.'): ['Young'], ('on.', 'Young'): ['catch'], ('Young', 'catch'): ['management'], ('catch', 'management'): ['sense'], ('management', 'sense'): ['technology.'], ('sense', 'technology.'): ['Physical'], ('technology.', 'Physical'): ['society'], ('Physical', 'society'): ['instead'], ('society', 'instead'): ['as.'], ('instead', 'as.'): ['Other'], ('as.', 'Other'): ['life'], ('Other', 'life'): ['edge'], ('life', 'edge'): ['network'], ('edge', 'network'): ['wall'], ('network', 'wall'): ['quite.'], ('wall', 'quite.'): ['Seem'], ('quite.', 'Seem'): ['shoulder'], ('Seem', 'shoulder'): ['future'], ('shoulder', 'future'): ['fall'], ('future', 'fall'): ['citizen'], ('fall', 'citizen'): ['about'], ('citizen', 'about'): ['reveal.'], ('about', 'reveal.'): ['Will'], ('reveal.', 'Will'): ['seven'], ('Will', 'seven'): ['medical'], ('seven', 'medical'): ['blood'], ('medical', 'blood'): ['personal.'], ('blood', 'personal.'): ['Current'], ('personal.', 'Current'): ['hear'], ('Current', 'hear'): ['claim'], ('hear', 'claim'): ['well'], ('claim', 'well'): ['two'], ('well', 'two'): ['truth'], ('two', 'truth'): ['out'], ('truth', 'out'): ['major.'], ('out', 'major.'): ['Upon'], ('major.', 'Upon'): ['these'], ('Upon', 'these'): ['story'], ('these', 'story'): ['film.'], ('story', 'film.'): ['Drive'], ('film.', 'Drive'): ['note'], ('Drive', 'note'): ['bad'], ('note', 'bad'): ['rule.'], ('bad', 'rule.'): ['She'], ('rule.', 'She'): ['campaign'], ('She', 'campaign'): ['little'], ('campaign', 'little'): ['near'], ('little', 'near'): ['enter'], ('near', 'enter'): ['their'], ('enter', 'their'): ['institution.'], ('their', 'institution.'): ['Up'], ('institution.', 'Up'): ['sense'], ('Up', 'sense'): ['ready'], ('sense', 'ready'): ['require'], ('ready', 'require'): ['human.'], ('require', 'human.'): ['Tonight'], ('human.', 'Tonight'): ['later'], ('Tonight', 'later'): ['easy'], ('later', 'easy'): ['ask'], ('easy', 'ask'): ['again'], ('ask', 'again'): ['network.'], ('again', 'network.'): ['Detail'], ('network.', 'Detail'): ['audience'], ('Detail', 'audience'): ['piece'], ('audience', 'piece'): ['director'], ('piece', 'director'): ['town'], ('director', 'town'): ['teacher'], ('town', 'teacher'): ['audience'], ('teacher', 'audience'): ['draw.'], ('audience', 'draw.'): ['Democrat'], ('draw.', 'Democrat'): ['car'], ('Democrat', 'car'): ['very'], ('car', 'very'): ['number'], ('very', 'number'): ['line'], ('number', 'line'): ['six'], ('line', 'six'): ['space.'], ('six', 'space.'): ['Best'], ('space.', 'Best'): ['issue'], ('Best', 'issue'): ['interest'], ('issue', 'interest'): ['level.'], ('interest', 'level.'): ['Pull'], ('level.', 'Pull'): ['worker'], ('Pull', 'worker'): ['better.'], ('worker', 'better.'): ['Song'], ('better.', 'Song'): ['body'], ('Song', 'body'): ['court'], ('body', 'court'): ['movie'], ('court', 'movie'): ['cell'], ('movie', 'cell'): ['contain.'], ('cell', 'contain.'): ['Economic'], ('contain.', 'Economic'): ['type'], ('Economic', 'type'): ['kitchen'], ('type', 'kitchen'): ['technology'], ('kitchen', 'technology'): ['nearly'], ('technology', 'nearly'): ['anything'], ('nearly', 'anything'): ['yourself.'], ('anything', 'yourself.'): ['Why'], ('yourself.', 'Why'): ['unit'], ('Why', 'unit'): ['support.'], ('unit', 'support.'): ['Magazine'], ('support.', 'Magazine'): ['degree'], ('Magazine', 'degree'): ['husband'], ('degree', 'husband'): ['around'], ('husband', 'around'): ['her'], ('around', 'her'): ['world.'], ('her', 'world.'): ['Unit'], ('world.', 'Unit'): ['size'], ('Unit', 'size'): ['expect'], ('size', 'expect'): ['recent'], ('expect', 'recent'): ['room.'], ('recent', 'room.'): ['Choice'], ('room.', 'Choice'): ['father'], ('Choice', 'father'): ['why'], ('father', 'why'): ['often'], ('why', 'often'): ['my'], ('often', 'my'): ['security'], ('my', 'security'): ['arm.'], ('security', 'arm.'): ['Live'], ('arm.', 'Live'): ['try'], ('Live', 'try'): ['most'], ('try', 'most'): ['arm'], ('most', 'arm'): ['meet'], ('arm', 'meet'): ['surface'], ('meet', 'surface'): ['attention'], ('surface', 'attention'): ['attack.'], ('attention', 'attack.'): ['Identify'], ('attack.', 'Identify'): ['walk'], ('Identify', 'walk'): ['now'], ('walk', 'now'): ['often'], ('now', 'often'): ['always.'], ('often', 'always.'): ['Price'], ('always.', 'Price'): ['north'], ('Price', 'north'): ['first'], ('north', 'first'): ['end'], ('first', 'end'): ['prove'], ('end', 'prove'): ['fire.'], ('prove', 'fire.'): ['How'], ('fire.', 'How'): ['public'], ('How', 'public'): ['feel'], ('public', 'feel'): ['first'], ('feel', 'first'): ['sell.'], ('first', 'sell.'): ['Leader'], ('sell.', 'Leader'): ['your'], ('Leader', 'your'): ['you.'], ('your', 'you.'): ['Mrs'], ('you.', 'Mrs'): ['media'], ('Mrs', 'media'): ['car'], ('media', 'car'): ['give.'], ('car', 'give.'): ['Hard'], ('give.', 'Hard'): ['citizen'], ('Hard', 'citizen'): ['street'], ('citizen', 'street'): ['region'], ('street', 'region'): ['particularly.'], ('region', 'particularly.'): ['Account'], ('particularly.', 'Account'): ['stage'], ('Account', 'stage'): ['federal'], ('stage', 'federal'): ['professional'], ('federal', 'professional'): ['voice'], ('professional', 'voice'): ['care'], ('voice', 'care'): ['break.'], ('care', 'break.'): ['Choice'], ('break.', 'Choice'): ['example'], ('Choice', 'example'): ['decision'], ('example', 'decision'): ['garden'], ('decision', 'garden'): ['reach'], ('garden', 'reach'): ['table'], ('reach', 'table'): ['measure.'], ('table', 'measure.'): ['Town'], ('measure.', 'Town'): ['suffer'], ('Town', 'suffer'): ['begin'], ('suffer', 'begin'): ['interest'], ('begin', 'interest'): ['everybody.'], ('interest', 'everybody.'): ['Side'], ('everybody.', 'Side'): ['PM'], ('Side', 'PM'): ['energy'], ('PM', 'energy'): ['scientist'], ('energy', 'scientist'): ['necessary'], ('scientist', 'necessary'): ['into.'], ('necessary', 'into.'): ['Away'], ('into.', 'Away'): ['third'], ('Away', 'third'): ['tough'], ('third', 'tough'): ['nation.'], ('tough', 'nation.'): ['Need'], ('nation.', 'Need'): ['involve'], ('Need', 'involve'): ['among'], ('involve', 'among'): ['half'], ('among', 'half'): ['value'], ('half', 'value'): ['win'], ('value', 'win'): ['always'], ('win', 'always'): ['group.'], ('always', 'group.'): ['Project'], ('group.', 'Project'): ['government'], ('Project', 'government'): ['nice'], ('government', 'nice'): ['themselves'], ('nice', 'themselves'): ['wind.'], ('themselves', 'wind.'): ['Understand'], ('wind.', 'Understand'): ['door'], ('Understand', 'door'): ['class'], ('door', 'class'): ['son.'], ('class', 'son.'): ['Agent'], ('son.', 'Agent'): ['say'], ('Agent', 'say'): ['forward'], ('say', 'forward'): ['us'], ('forward', 'us'): ['soon'], ('us', 'soon'): ['ten.'], ('soon', 'ten.'): ['Environment'], ('ten.', 'Environment'): ['skin'], ('Environment', 'skin'): ['blue'], ('skin', 'blue'): ['the'], ('blue', 'the'): ['teach.'], ('the', 'teach.'): ['Staff'], ('teach.', 'Staff'): ['least'], ('Staff', 'least'): ['figure'], ('least', 'figure'): ['somebody'], ('figure', 'somebody'): ['dinner.'], ('somebody', 'dinner.'): ['Process'], ('dinner.', 'Process'): ['huge'], ('Process', 'huge'): ['everything.'], ('huge', 'everything.'): ['Go'], ('everything.', 'Go'): ['meeting'], ('Go', 'meeting'): ['quickly'], ('meeting', 'quickly'): ['such'], ('quickly', 'such'): ['former.'], ('such', 'former.'): ['Boy'], ('former.', 'Boy'): ['wife'], ('Boy', 'wife'): ['condition.'], ('wife', 'condition.'): ['Board'], ('condition.', 'Board'): ['its'], ('Board', 'its'): ['rock.'], ('its', 'rock.'): ['Job'], ('rock.', 'Job'): ['worker'], ('Job', 'worker'): ['break'], ('worker', 'break'): ['tonight'], ('break', 'tonight'): ['couple'], ('tonight', 'couple'): ['and.'], ('couple', 'and.'): ['Mind'], ('and.', 'Mind'): ['southern'], ('Mind', 'southern'): ['rather.'], ('southern', 'rather.'): ['Hair'], ('rather.', 'Hair'): ['attorney'], ('Hair', 'attorney'): ['professional'], ('attorney', 'professional'): ['form'], ('professional', 'form'): ['finish.'], ('form', 'finish.'): ['Rest'], ('finish.', 'Rest'): ['feel'], ('Rest', 'feel'): ['finally'], ('feel', 'finally'): ['impact.'], ('finally', 'impact.'): ['Never'], ('impact.', 'Never'): ['court'], ('Never', 'court'): ['professor'], ('court', 'professor'): ['here'], ('professor', 'here'): ['security.'], ('here', 'security.'): ['Past'], ('security.', 'Past'): ['feeling'], ('Past', 'feeling'): ['nature'], ('feeling', 'nature'): ['a.'], ('nature', 'a.'): ['Decision'], ('a.', 'Decision'): ['size'], ('Decision', 'size'): ['parent'], ('size', 'parent'): ['focus'], ('parent', 'focus'): ['kid.'], ('focus', 'kid.'): ['List'], ('kid.', 'List'): ['top'], ('List', 'top'): ['somebody'], ('top', 'somebody'): ['college'], ('somebody', 'college'): ['be'], ('college', 'be'): ['middle'], ('be', 'middle'): ['plan.'], ('middle', 'plan.'): ['Behavior'], ('plan.', 'Behavior'): ['weight'], ('Behavior', 'weight'): ['dog'], ('weight', 'dog'): ['financial'], ('dog', 'financial'): ['southern'], ('financial', 'southern'): ['challenge.'], ('southern', 'challenge.'): ['Worker'], ('challenge.', 'Worker'): ['particularly'], ('Worker', 'particularly'): ['shoulder'], ('particularly', 'shoulder'): ['lay'], ('shoulder', 'lay'): ['though.'], ('lay', 'though.'): ['Responsibility'], ('though.', 'Responsibility'): ['himself'], ('Responsibility', 'himself'): ['hundred'], ('himself', 'hundred'): ['challenge'], ('hundred', 'challenge'): ['reach.'], ('challenge', 'reach.'): ['Sing'], ('reach.', 'Sing'): ['despite'], ('Sing', 'despite'): ['sound'], ('despite', 'sound'): ['receive.'], ('sound', 'receive.'): ['Anyone'], ('receive.', 'Anyone'): ['eat'], ('Anyone', 'eat'): ['summer'], ('eat', 'summer'): ['lead'], ('summer', 'lead'): ['soon'], ('lead', 'soon'): ['property'], ('soon', 'property'): ['write.'], ('property', 'write.'): ['Wear'], ('write.', 'Wear'): ['through'], ('Wear', 'through'): ['partner'], ('through', 'partner'): ['rest'], ('partner', 'rest'): ['measure'], ('rest', 'measure'): ['store.'], ('measure', 'store.'): ['Knowledge'], ('store.', 'Knowledge'): ['city'], ('Knowledge', 'city'): ['technology'], ('city', 'technology'): ['late'], ('technology', 'late'): ['seem'], ('late', 'seem'): ['style'], ('seem', 'style'): ['everyone.'], ('style', 'everyone.'): ['Machine'], ('everyone.', 'Machine'): ['dream'], ('Machine', 'dream'): ['key'], ('dream', 'key'): ['require'], ('key', 'require'): ['doctor'], ('require', 'doctor'): ['from'], ('doctor', 'from'): ['throw.'], ('from', 'throw.'): ['Catch'], ('throw.', 'Catch'): ['discuss'], ('Catch', 'discuss'): ['really'], ('discuss', 'really'): ['relationship.'], ('really', 'relationship.'): ['Imagine'], ('relationship.', 'Imagine'): ['my'], ('Imagine', 'my'): ['indeed'], ('my', 'indeed'): ['deal'], ('indeed', 'deal'): ['information'], ('deal', 'information'): ['toward.'], ('information', 'toward.'): ['Watch'], ('toward.', 'Watch'): ['affect'], ('Watch', 'affect'): ['thing'], ('affect', 'thing'): ['offer'], ('thing', 'offer'): ['local'], ('offer', 'local'): ['wall'], ('local', 'wall'): ['fear'], ('wall', 'fear'): ['hope.'], ('fear', 'hope.'): ['Section'], ('hope.', 'Section'): ['national'], ('Section', 'national'): ['owner'], ('national', 'owner'): ['determine'], ('owner', 'determine'): ['detail'], ('determine', 'detail'): ['job'], ('detail', 'job'): ['ahead.'], ('job', 'ahead.'): ['Protect'], ('ahead.', 'Protect'): ['something'], ('Protect', 'something'): ['right'], ('something', 'right'): ['subject'], ('right', 'subject'): ['try'], ('subject', 'try'): ['wonder.'], ('try', 'wonder.'): ['Agree'], ('wonder.', 'Agree'): ['hour'], ('Agree', 'hour'): ['north'], ('hour', 'north'): ['agree'], ('north', 'agree'): ['poor'], ('agree', 'poor'): ['career'], ('poor', 'career'): ['left.'], ('career', 'left.'): ['Here'], ('left.', 'Here'): ['deep'], ('Here', 'deep'): ['force'], ('deep', 'force'): ['seven'], ('force', 'seven'): ['here.'], ('seven', 'here.'): ['Strong'], ('here.', 'Strong'): ['like'], ('Strong', 'like'): ['see'], ('like', 'see'): ['appear'], ('see', 'appear'): ['weight.'], ('appear', 'weight.'): ['Practice'], ('weight.', 'Practice'): ['sit'], ('Practice', 'sit'): ['prepare'], ('sit', 'prepare'): ['senior'], ('prepare', 'senior'): ['wear.'], ('senior', 'wear.'): ['Stuff'], ('wear.', 'Stuff'): ['perform'], ('Stuff', 'perform'): ['draw'], ('perform', 'draw'): ['list'], ('draw', 'list'): ['boy.'], ('list', 'boy.'): ['Record'], ('boy.', 'Record'): ['short'], ('Record', 'short'): ['cold'], ('short', 'cold'): ['parent'], ('cold', 'parent'): ['security'], ('parent', 'security'): ['boy'], ('security', 'boy'): ['standard.'], ('boy', 'standard.'): ['Blue'], ('standard.', 'Blue'): ['agent'], ('Blue', 'agent'): ['find'], ('agent', 'find'): ['quality'], ('find', 'quality'): ['when.'], ('quality', 'when.'): ['Away'], ('when.', 'Away'): ['real'], ('Away', 'real'): ['physical'], ('real', 'physical'): ['big'], ('physical', 'big'): ['significant.'], ('big', 'significant.'): ['South'], ('significant.', 'South'): ['someone'], ('South', 'someone'): ['not'], ('someone', 'not'): ['American'], ('not', 'American'): ['mouth'], ('American', 'mouth'): ['product'], ('mouth', 'product'): ['attention'], ('product', 'attention'): ['positive.'], ('attention', 'positive.'): ['Support'], ('positive.', 'Support'): ['state'], ('Support', 'state'): ['black.'], ('state', 'black.'): ['Religious'], ('black.', 'Religious'): ['itself'], ('Religious', 'itself'): ['safe'], ('itself', 'safe'): ['whole'], ('safe', 'whole'): ['establish'], ('whole', 'establish'): ['space'], ('establish', 'space'): ['Mrs.'], ('space', 'Mrs.'): ['Let'], ('Mrs.', 'Let'): ['stay'], ('Let', 'stay'): ['or'], ('stay', 'or'): ['focus'], ('or', 'focus'): ['early'], ('focus', 'early'): ['various'], ('early', 'various'): ['everything.'], ('various', 'everything.'): ['During'], ('everything.', 'During'): ['let'], ('During', 'let'): ['particular'], ('let', 'particular'): ['her'], ('particular', 'her'): ['agreement'], ('her', 'agreement'): ['surface'], ('agreement', 'surface'): ['consider.'], ('surface', 'consider.'): ['Something'], ('consider.', 'Something'): ['future'], ('Something', 'future'): ['they'], ('future', 'they'): ['red'], ('they', 'red'): ['everybody'], ('red', 'everybody'): ['act.'], ('everybody', 'act.'): ['Beat'], ('act.', 'Beat'): ['result'], ('Beat', 'result'): ['major'], ('result', 'major'): ['serve'], ('major', 'serve'): ['real.'], ('serve', 'real.'): ['Society'], ('real.', 'Society'): ['behavior'], ('Society', 'behavior'): ['develop'], ('behavior', 'develop'): ['reality'], ('develop', 'reality'): ['fill'], ('reality', 'fill'): ['ok'], ('fill', 'ok'): ['list.'], ('ok', 'list.'): ['Gas'], ('list.', 'Gas'): ['you'], ('Gas', 'you'): ['nearly'], ('you', 'nearly'): ['goal'], ('nearly', 'goal'): ['law'], ('goal', 'law'): ['fill'], ('law', 'fill'): ['discover.'], ('fill', 'discover.'): ['Firm'], ('discover.', 'Firm'): ['sea'], ('Firm', 'sea'): ['week'], ('sea', 'week'): ['real'], ('week', 'real'): ['course.'], ('real', 'course.'): ['Right'], ('course.', 'Right'): ['with'], ('Right', 'with'): ['modern'], ('with', 'modern'): ['executive'], ('modern', 'executive'): ['beyond.'], ('executive', 'beyond.'): ['Fast'], ('beyond.', 'Fast'): ['guess'], ('Fast', 'guess'): ['few'], ('guess', 'few'): ['remain'], ('few', 'remain'): ['call.'], ('remain', 'call.'): ['Window'], ('call.', 'Window'): ['network'], ('Window', 'network'): ['recently.'], ('network', 'recently.'): ['Bill'], ('recently.', 'Bill'): ['activity'], ('Bill', 'activity'): ['expect'], ('activity', 'expect'): ['long'], ('expect', 'long'): ['future'], ('long', 'future'): ['whole'], ('future', 'whole'): ['education.'], ('whole', 'education.'): ['Box'], ('education.', 'Box'): ['assume'], ('Box', 'assume'): ['man'], ('assume', 'man'): ['officer'], ('man', 'officer'): ['rather'], ('officer', 'rather'): ['charge'], ('rather', 'charge'): ['specific.'], ('charge', 'specific.'): ['Yes'], ('specific.', 'Yes'): ['budget'], ('Yes', 'budget'): ['share'], ('budget', 'share'): ['paper.'], ('share', 'paper.'): ['Difficult'], ('paper.', 'Difficult'): ['mission'], ('Difficult', 'mission'): ['late'], ('mission', 'late'): ['kind'], ('late', 'kind'): ['team'], ('kind', 'team'): ['wrong'], ('team', 'wrong'): ['figure'], ('wrong', 'figure'): ['perform.'], ('figure', 'perform.'): ['Way'], ('perform.', 'Way'): ['debate'], ('Way', 'debate'): ['decision'], ('debate', 'decision'): ['produce.'], ('decision', 'produce.'): ['Dream'], ('produce.', 'Dream'): ['necessary'], ('Dream', 'necessary'): ['choose'], ('necessary', 'choose'): ['impact.'], ('choose', 'impact.'): ['Like'], ('impact.', 'Like'): ['allow'], ('Like', 'allow'): ['explain'], ('allow', 'explain'): ['executive'], ('explain', 'executive'): ['teacher'], ('executive', 'teacher'): ['author'], ('teacher', 'author'): ['do'], ('author', 'do'): ['enough.'], ('do', 'enough.'): ['Operation'], ('enough.', 'Operation'): ['sound'], ('Operation', 'sound'): ['cup'], ('sound', 'cup'): ['boy'], ('cup', 'boy'): ['different'], ('boy', 'different'): ['chance'], ('different', 'chance'): ['enter'], ('chance', 'enter'): ['central.'], ('enter', 'central.'): ['Society'], ('central.', 'Society'): ['organization'], ('Society', 'organization'): ['station'], ('organization', 'station'): ['TV.'], ('station', 'TV.'): ['Buy'], ('TV.', 'Buy'): ['read'], ('Buy', 'read'): ['record'], ('read', 'record'): ['wall'], ('record', 'wall'): ['matter'], ('wall', 'matter'): ['management.'], ('matter', 'management.'): ['Always'], ('management.', 'Always'): ['it'], ('Always', 'it'): ['focus'], ('it', 'focus'): ['economy'], ('focus', 'economy'): ['before'], ('economy', 'before'): ['while'], ('before', 'while'): ['structure'], ('while', 'structure'): ['offer.'], ('structure', 'offer.'): ['Yourself'], ('offer.', 'Yourself'): ['public'], ('Yourself', 'public'): ['especially.'], ('public', 'especially.'): ['Like'], ('especially.', 'Like'): ['prepare'], ('Like', 'prepare'): ['trouble'], ('prepare', 'trouble'): ['consider.'], ('trouble', 'consider.'): ['Play'], ('consider.', 'Play'): ['man'], ('Play', 'man'): ['before'], ('man', 'before'): ['girl'], ('before', 'girl'): ['four'], ('girl', 'four'): ['prove.'], ('four', 'prove.'): ['Form'], ('prove.', 'Form'): ['really'], ('Form', 'really'): ['explain'], ('really', 'explain'): ['war.'], ('explain', 'war.'): ['Already'], ('war.', 'Already'): ['because'], ('Already', 'because'): ['education'], ('because', 'education'): ['break'], ('education', 'break'): ['significant'], ('break', 'significant'): ['ten'], ('significant', 'ten'): ['stay.'], ('ten', 'stay.'): ['Price'], ('stay.', 'Price'): ['my'], ('Price', 'my'): ['including.'], ('my', 'including.'): ['Gun'], ('including.', 'Gun'): ['series'], ('Gun', 'series'): ['personal'], ('series', 'personal'): ['service'], ('personal', 'service'): ['data'], ('service', 'data'): ['near'], ('data', 'near'): ['until.'], ('near', 'until.'): ['Thing'], ('until.', 'Thing'): ['machine'], ('Thing', 'machine'): ['ahead'], ('machine', 'ahead'): ['picture'], ('ahead', 'picture'): ['son'], ('picture', 'son'): ['report.']}\n",
            "Generated sentence: Lorem ipsum\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from faker import Faker\n",
        "\n",
        "def generate_lorem_ipsum_paragraphs(num_paragraphs=5, sentences_per_paragraph=5):\n",
        "    fake = Faker()\n",
        "    Faker.seed(42)  # Setting seed for reproducibility\n",
        "    lorem_ipsum_text = \"\"\n",
        "    for _ in range(num_paragraphs):\n",
        "        paragraph = fake.paragraphs(nb=sentences_per_paragraph)\n",
        "        lorem_ipsum_text += \"\\n\\n\".join(paragraph) + \"\\n\\n\"\n",
        "    return lorem_ipsum_text\n",
        "\n",
        "def save_text_to_file(text, filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text)\n",
        "\n",
        "def read_text(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def tokenize_text(text):\n",
        "    return text.split()\n",
        "\n",
        "def create_markov_chain(tokens, chain_length):\n",
        "    chain = {}\n",
        "    for i in range(len(tokens) - chain_length):\n",
        "        prefix = tuple(tokens[i:i + chain_length])\n",
        "        suffix = tokens[i + chain_length]\n",
        "        if prefix in chain:\n",
        "            chain[prefix].append(suffix)\n",
        "        else:\n",
        "            chain[prefix] = [suffix]\n",
        "    return chain\n",
        "\n",
        "def generate_sentence(chain, start_words, num_generated):\n",
        "    sentence = list(start_words)\n",
        "    current_prefix = tuple(start_words)\n",
        "\n",
        "    for _ in range(num_generated):\n",
        "        if current_prefix not in chain:\n",
        "            break\n",
        "        next_word = random.choice(chain[current_prefix])\n",
        "        sentence.append(next_word)\n",
        "        current_prefix = tuple(sentence[-len(start_words):])\n",
        "\n",
        "    return ' '.join(sentence)\n",
        "\n",
        "def generate(filename, start_words, chain_length, num_generated):\n",
        "    text = read_text(filename)\n",
        "    tokens = tokenize_text(text)\n",
        "    chain = create_markov_chain(tokens, chain_length)\n",
        "\n",
        "    # Debugging print statements\n",
        "    print(\"Tokens:\", tokens)\n",
        "    print(\"Chain:\", chain)\n",
        "\n",
        "    return generate_sentence(chain, start_words, num_generated)\n",
        "\n",
        "# Generate Lorem Ipsum text\n",
        "lorem_ipsum_text = generate_lorem_ipsum_paragraphs(num_paragraphs=10, sentences_per_paragraph=5)\n",
        "\n",
        "# Save the text to a file\n",
        "filename = \"LoremIpsum.txt\"\n",
        "save_text_to_file(lorem_ipsum_text, filename)\n",
        "print(f\"Lorem Ipsum text saved to '{filename}'\")\n",
        "\n",
        "# Example usage:\n",
        "start_words = ['Lorem', 'ipsum']\n",
        "chain_length = 2  # Adjust the chain length as needed\n",
        "num_generated = 50  # Adjust the number of words to generate as needed\n",
        "\n",
        "generated_sentence = generate(filename, start_words, chain_length, num_generated)\n",
        "print(\"Generated sentence:\", generated_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_word():\n",
        "    # Generate a random word of random length between 1 and 10 characters\n",
        "    word_length = random.randint(1, 10)\n",
        "    return ''.join(random.choice(string.ascii_lowercase) for _ in range(word_length))\n",
        "\n",
        "def generate_random_sentence(num_words):\n",
        "    # Generate a sentence with the specified number of random words\n",
        "    return ' '.join(generate_random_word() for _ in range(num_words))\n",
        "\n",
        "# Example usage:\n",
        "num_words = 50  # Adjust the number of words to generate as needed\n",
        "random_sentence = generate_random_sentence(num_words)\n",
        "print(random_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QHz5vKBA9U2",
        "outputId": "12185703-94db-421f-dcee-b4b947c23d75"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my gfesozxqz ukxhlhf f iejyppzq hkt iic nwyahvdbjs hx xls pl iwccvlgscb qanxu nzh mcwpltbf vrcdebffo qowkc y bihcbptf hhtdwyr l uzulaaeh qycwblo yejr ixnjtvj v lo sb kinshuayn rzjt sjqjhqp yubjqcwqsn sftbaul rxbeoc gxx fjw rxz eptl e qc eqja qzhxuwk bmoaxosne poquxypnk rf ohtud avxhlvkxt znfji r wcnjacx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_word():\n",
        "    # Generate a random word of random length between 1 and 10 characters\n",
        "    word_length = random.randint(1, 10)\n",
        "    return ''.join(random.choice(string.ascii_lowercase) for _ in range(word_length))\n",
        "\n",
        "def generate_sentence_with_start_words(start_words, num_words):\n",
        "    # Start the sentence with the given start words\n",
        "    sentence = start_words[:]\n",
        "\n",
        "    # Generate additional random words to complete the sentence\n",
        "    remaining_words = num_words - len(start_words)\n",
        "    if remaining_words > 0:\n",
        "        sentence.extend(generate_random_word() for _ in range(remaining_words))\n",
        "\n",
        "    return ' '.join(sentence)\n",
        "\n",
        "# Example usage:\n",
        "start_words = ['The', 'quick', 'brown']\n",
        "num_words = 10  # Adjust the total number of words in the sentence as needed\n",
        "random_sentence = generate_sentence_with_start_words(start_words, num_words)\n",
        "print(random_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAwWhrOoBSmY",
        "outputId": "892b1164-e9cf-4802-d44a-2eea64ddbb8a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick brown xgmoj t ofodfd pbkmkiy cxekyzn jyqfcw o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_random_sentence_generation():\n",
        "    test_cases = [\n",
        "        (['The'], 10),\n",
        "        (['The', 'quick'], 15),\n",
        "        (['The', 'quick', 'brown'], 20),\n",
        "        (['The', 'quick', 'brown', 'fox'], 25),\n",
        "        (['The', 'quick', 'brown', 'fox', 'jumps'], 30),\n",
        "        (['123'], 10),\n",
        "        (['$#@'], 10),\n",
        "        (['AbCdEfG'], 10),\n",
        "        (['résumé'], 10),\n",
        "        (['antidisestablishmentarianism'], 10),\n",
        "        (['a', 'bb', 'ccc'], 10),\n",
        "        (['Hello,', 'world!'], 10),\n",
        "        (['Start', 'with', 'start', 'words', '...'], 10),\n",
        "        ([''], 10),\n",
        "        (['   '], 10),\n",
        "    ]\n",
        "\n",
        "    for i, (start_words, num_words) in enumerate(test_cases, start=1):\n",
        "        print(f\"Test Case {i}: Start Words: {start_words}, Total Words: {num_words}\")\n",
        "        random_sentence = generate_sentence_with_start_words(start_words, num_words)\n",
        "        print(\"Generated Sentence:\", random_sentence)\n",
        "        assert random_sentence.startswith(' '.join(start_words)), \"Start words not found at the beginning of the sentence\"\n",
        "        assert len(random_sentence.split()) == num_words, \"Generated sentence has incorrect number of words\"\n",
        "        print(\"Test Passed\\n\")\n",
        "\n",
        "# Run the test cases\n",
        "test_random_sentence_generation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U5_XtT7sBVib",
        "outputId": "e0751e05-6739-43a1-c1b4-53d67c75136a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 1: Start Words: ['The'], Total Words: 10\n",
            "Generated Sentence: The gevwzascgi uiknjudi pceofgl gshelptkdm omjgytox tor iuyadihpcw d odbgkgluur\n",
            "Test Passed\n",
            "\n",
            "Test Case 2: Start Words: ['The', 'quick'], Total Words: 15\n",
            "Generated Sentence: The quick lb txu tvxtcp dcyrfjt rldhbhrqku bthu xtkdnbmkvh vh jf zegrvm fao qcqyyugsm mbmp\n",
            "Test Passed\n",
            "\n",
            "Test Case 3: Start Words: ['The', 'quick', 'brown'], Total Words: 20\n",
            "Generated Sentence: The quick brown z qaev lzlhb qrc ec oxfrtk ymbfzsb gqcdrowm mbthevie p smg xvyuch yzkwsuz c nqfcw xpnaomnic gmgzxtswp\n",
            "Test Passed\n",
            "\n",
            "Test Case 4: Start Words: ['The', 'quick', 'brown', 'fox'], Total Words: 25\n",
            "Generated Sentence: The quick brown fox vkgpkfntj snamd klmxz ybcnarx ilkfrg raobrpckkv lcbic kc smmricduy igtrl ivfks v fn juupqtlyis qgnyyjpbi jymbczqi u aqhxwu ycttvqo rixabr frxgm\n",
            "Test Passed\n",
            "\n",
            "Test Case 5: Start Words: ['The', 'quick', 'brown', 'fox', 'jumps'], Total Words: 30\n",
            "Generated Sentence: The quick brown fox jumps fpmiualu ghlc bo jayzbvri qrfrsdpgp ns kmbiqduj jdlz vlwn apzdcjz suapko bdkxxiksb id ymmukvsec jhtkm kmaqx ntdlcxkt g kff wme onnve zbirw seg di gps\n",
            "Test Passed\n",
            "\n",
            "Test Case 6: Start Words: ['123'], Total Words: 10\n",
            "Generated Sentence: 123 oetp gxgewfgn jwxhwvybwk w sfcjldykkc jtnbwp ib qjsxo lsgs\n",
            "Test Passed\n",
            "\n",
            "Test Case 7: Start Words: ['$#@'], Total Words: 10\n",
            "Generated Sentence: $#@ huaynta stpws t cpmpt bnvwmlogz j bachwchbt ae uwypgol\n",
            "Test Passed\n",
            "\n",
            "Test Case 8: Start Words: ['AbCdEfG'], Total Words: 10\n",
            "Generated Sentence: AbCdEfG nlvsdlbb bb qdomwie nsj eqx rskxw vngllxdqhj mpbqrus uiro\n",
            "Test Passed\n",
            "\n",
            "Test Case 9: Start Words: ['résumé'], Total Words: 10\n",
            "Generated Sentence: résumé mjzefc subeg q frv lv mjvpw xjyu fhxntnpwb ocaoarhp\n",
            "Test Passed\n",
            "\n",
            "Test Case 10: Start Words: ['antidisestablishmentarianism'], Total Words: 10\n",
            "Generated Sentence: antidisestablishmentarianism xylmufwukx lfuewi mc gajayxn abyr ao exy noduqepa vpcyrwdmf\n",
            "Test Passed\n",
            "\n",
            "Test Case 11: Start Words: ['a', 'bb', 'ccc'], Total Words: 10\n",
            "Generated Sentence: a bb ccc no mv prlcgrj eufars z eevbiyuk olqtx\n",
            "Test Passed\n",
            "\n",
            "Test Case 12: Start Words: ['Hello,', 'world!'], Total Words: 10\n",
            "Generated Sentence: Hello, world! dlmxrc qckpfc x x tieef itqv qdjgoz zfeqvekwq\n",
            "Test Passed\n",
            "\n",
            "Test Case 13: Start Words: ['Start', 'with', 'start', 'words', '...'], Total Words: 10\n",
            "Generated Sentence: Start with start words ... ioxjml anii mhv gvzw gyczxpoqjs\n",
            "Test Passed\n",
            "\n",
            "Test Case 14: Start Words: [''], Total Words: 10\n",
            "Generated Sentence:  vhtaq kj qucuaeuf lefp ffmimqdhkx m soqjact a rmqemdt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Generated sentence has incorrect number of words",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-00ef7724bf6e>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Run the test cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtest_random_sentence_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-00ef7724bf6e>\u001b[0m in \u001b[0;36mtest_random_sentence_generation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generated Sentence:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mrandom_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Start words not found at the beginning of the sentence\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Generated sentence has incorrect number of words\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Passed\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Generated sentence has incorrect number of words"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_random_sentence_generation():\n",
        "    test_cases = [\n",
        "        (['The'], 5),  # Start with one word\n",
        "        (['The', 'quick'], 10),  # Start with two words\n",
        "        (['The', 'quick', 'brown'], 7),  # Start with three words\n",
        "        (['Hello'], 3),  # Start with one word\n",
        "        (['Hello', 'world'], 8),  # Start with two words\n",
        "        (['This', 'is', 'a', 'test'], 6),  # Start with four words\n",
        "        (['Lorem'], 4),  # Start with one word\n",
        "        (['Lorem', 'ipsum'], 9),  # Start with two words\n",
        "        (['Lorem', 'ipsum', 'dolor'], 12),  # Start with three words\n",
        "        (['Python'], 5),  # Start with one word\n",
        "        (['Python', 'programming'], 10),  # Start with two words\n",
        "        (['Artificial', 'intelligence'], 7),  # Start with two words\n",
        "        (['OpenAI'], 3),  # Start with one word\n",
        "        (['Natural', 'Language', 'Processing'], 8),  # Start with three words\n",
        "        (['Deep', 'Learning', 'models', 'are'], 6),  # Start with four words\n",
        "    ]\n",
        "\n",
        "    for i, (start_words, num_words) in enumerate(test_cases, start=1):\n",
        "        print(f\"Test Case {i}:\")\n",
        "        print(\"Start Words:\", start_words)\n",
        "        print(\"Number of Words:\", num_words)\n",
        "        random_sentence = generate_sentence_with_start_words(start_words, num_words)\n",
        "        print(\"Generated Sentence:\", random_sentence)\n",
        "        print()\n",
        "\n",
        "# Perform testing\n",
        "test_random_sentence_generation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fmdd7R1CP1N",
        "outputId": "3c33a41a-f5b8-4a1d-e605-68decb34275e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 1:\n",
            "Start Words: ['The']\n",
            "Number of Words: 5\n",
            "Generated Sentence: The poaa x otxf hxguqak\n",
            "\n",
            "Test Case 2:\n",
            "Start Words: ['The', 'quick']\n",
            "Number of Words: 10\n",
            "Generated Sentence: The quick isajxcx yyxf ajrfucui g oszkiwxsl qz z b\n",
            "\n",
            "Test Case 3:\n",
            "Start Words: ['The', 'quick', 'brown']\n",
            "Number of Words: 7\n",
            "Generated Sentence: The quick brown eqpkndezz mpgurone yuuqgwzsxu tdbjrzdy\n",
            "\n",
            "Test Case 4:\n",
            "Start Words: ['Hello']\n",
            "Number of Words: 3\n",
            "Generated Sentence: Hello wulkunuml lqxb\n",
            "\n",
            "Test Case 5:\n",
            "Start Words: ['Hello', 'world']\n",
            "Number of Words: 8\n",
            "Generated Sentence: Hello world dckt xqxbqul va givtaarzwj xjfv ljpqbqqpju\n",
            "\n",
            "Test Case 6:\n",
            "Start Words: ['This', 'is', 'a', 'test']\n",
            "Number of Words: 6\n",
            "Generated Sentence: This is a test tcckxyaq scgaynwcqr\n",
            "\n",
            "Test Case 7:\n",
            "Start Words: ['Lorem']\n",
            "Number of Words: 4\n",
            "Generated Sentence: Lorem hxpy qdizwjs cdi\n",
            "\n",
            "Test Case 8:\n",
            "Start Words: ['Lorem', 'ipsum']\n",
            "Number of Words: 9\n",
            "Generated Sentence: Lorem ipsum lbbxckkibo syxoilp ceiom ttkmlhl hzeflxwlp e kvmbzoqxq\n",
            "\n",
            "Test Case 9:\n",
            "Start Words: ['Lorem', 'ipsum', 'dolor']\n",
            "Number of Words: 12\n",
            "Generated Sentence: Lorem ipsum dolor qjxpd mbctxbhgj tpzoceokek jehnixn qf dcxb x hs qfbnwym\n",
            "\n",
            "Test Case 10:\n",
            "Start Words: ['Python']\n",
            "Number of Words: 5\n",
            "Generated Sentence: Python emglsgo tdvfv nvj ozq\n",
            "\n",
            "Test Case 11:\n",
            "Start Words: ['Python', 'programming']\n",
            "Number of Words: 10\n",
            "Generated Sentence: Python programming gfzlx kbrbt oprkgu vgxx olqqwj gwzrgx hd ufi\n",
            "\n",
            "Test Case 12:\n",
            "Start Words: ['Artificial', 'intelligence']\n",
            "Number of Words: 7\n",
            "Generated Sentence: Artificial intelligence voql hepvxveump tmmfh qtfryeisd ma\n",
            "\n",
            "Test Case 13:\n",
            "Start Words: ['OpenAI']\n",
            "Number of Words: 3\n",
            "Generated Sentence: OpenAI kbta udsjhhqaxv\n",
            "\n",
            "Test Case 14:\n",
            "Start Words: ['Natural', 'Language', 'Processing']\n",
            "Number of Words: 8\n",
            "Generated Sentence: Natural Language Processing t bzj qbbbd c ky\n",
            "\n",
            "Test Case 15:\n",
            "Start Words: ['Deep', 'Learning', 'models', 'are']\n",
            "Number of Words: 6\n",
            "Generated Sentence: Deep Learning models are yjfbycp enbz\n",
            "\n"
          ]
        }
      ]
    }
  ]
}